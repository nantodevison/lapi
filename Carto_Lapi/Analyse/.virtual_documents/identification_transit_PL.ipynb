get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")
import sys #c'est pas propre mais pour le moment pour importer mes modules perso dans le notebook je ne sais pas faire
sys.path.append(r'C:\Users\martin.schoreisz\git\Outils\Outils\Martin_Perso')
import Import_Forme as i_f
import transit
import trajets
from trajets import PasDePlError
import Correction_transit as corr
import Traitements_complets as tc
import graphs as g
import Resultats as r
import Nationalite as n
import pandas as pd
import numpy as np
import altair as alt
from altair_saver import save
from textwrap import wrap
pd.set_option('display.max_colwidth', 500)
pd.set_option('display.max_columns', 50)
pd.set_option('display.max_rows', 100)
alt.data_transformers.enable('default', max_rows=None)
import os, math, re


df_passages_immat_ok = r.ouvrir_donnees(r'C:\Users\martin.schoreisz\Box\Cerema\60-SO\66-DM\6615-PMD\080-Dossiers\LAPI\C17SI0073_LAPI\Traitements\python\donnees_sources\df_passages_immat_ok.json')
df_passages_immat_ok.set_index('created', inplace=True)


dico_df_od_final = {}
dico_df_od_final['df_od_final_marge60'] = r.ouvrir_donnees(
    r'C:\Users\martin.schoreisz\Box\Cerema\60-SO\66-DM\6615-PMD\080-Dossiers\LAPI\C17SI0073_LAPI\Projet Rapport\resultats\df_od_final_marge60.json')


get_ipython().run_line_magic("time", " df_passages_source, df_plaques, df_immat=i_f.ouvrir_fichier_lapi_final('2019-01-22 23:00:00','2019-02-13 22:59:59')")


#export au format svg des données TV
for i in range(1,20) :
    chemin=os.path.join(r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\graphs\nb_veh_J_cam',f'cam{i}.svg')
    g.graph_nb_veh_jour_camera_multi_j(df_passages,'2019-01-23 00:00:00','2019-01-23 23:59:59',i,22).save(chemin)


get_ipython().run_line_magic("time", " df_passages_source=i_f.recalage_passage_1h(df_passages_source)")


get_ipython().run_line_magic("time", " df_passages2=i_f.affecter_type(df_passages_source,df_immat)")


get_ipython().run_line_magic("time", " df_passages3=i_f.affecter_type_nuit(df_passages2)")


df_passages_pl=df_passages3.loc[df_passages3['l']==1].copy()


get_ipython().run_cell_magic("time", " ", """df_passages_pl_ss_doublons=i_f.supprimer_doublons(df_passages_pl)""")


get_ipython().run_cell_magic("time", " ", """#pour traitement
passg_pl_recale_cam10=i_f.recalage_cam10(df_passages_pl_ss_doublons)""")


get_ipython().run_cell_magic("time", " ", """df_passages_immat_ok, df_immat_suppr=i_f.filtre_plaque_non_valable(passg_pl_recale_cam10, df_plaques)""")


#comparaison des données sur une camera
g.comp_lapi_gest(df_passages_immat_ok,i_f.donnees_gest_jour,7)


# comparaison des données sur plsuieurs camera
g.comp_lapi_gest_multicam(df_passages_immat_ok,i_f.donnees_gest_jour)


get_ipython().run_line_magic("time", " dico_od,  dico_passag, dico_tps_max=transit.transit_temps_complet('2019-01-22 00:00:00',23,df_passages_immat_ok)")


get_ipython().run_line_magic("time", " g.graph_trajet_multiple(dico_od,'2019-01-23','A10-A63',22)")


get_ipython().run_cell_magic("time", "", """r.save_donnees(dico_od, r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\dico_base\dico_od.json')
r.save_donnees(dico_passag, r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\dico_base\dico_passag.json')
r.save_donnees(dico_tps_max, r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\dico_base\dico_tps_max.json')""")


get_ipython().run_line_magic("time", " dixco_tpsmax_corrige=corr.corriger_df_tps_parcours(dico_tps_max)")


r.save_donnees(dixco_tpsmax_corrige, r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\dico_base\dixco_tpsmax_corrige.json')


#affectation des temps de parcours de reference
get_ipython().run_line_magic("time", " df_transit_tps_ref=transit.jointure_temps_reel_theorique(dico_od,dixco_tpsmax_corrige,i_f.liste_complete_trajet)")


#df des transit avec marge 0 ss extrapolation
get_ipython().run_line_magic("time", " df_transit_marge0_ss_extrapolation=transit.identifier_transit(df_transit_tps_ref, 0)")


r.save_donnees(df_transit_marge0_ss_extrapolation, r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\df_marge0\df_transit_marge0_ss_extrapolation.json')


g.graph_transit_filtre_multiple(df_transit_marge0_ss_extrapolation,'2019-01-23 00:00:00', '2019-01-23 23:59:59','N10-A660',22)


alt.VConcatChart(vconcat=([g.graph_transit_filtre(df_transit_marge0_ss_extrapolation,'2019-02-07 00:00:00', '2019-02-07 23:59:59',trajet)
 for trajet in ['N10-A63', 'A63-N10','A63-A10','A10-A63','N10-A62','A62-N10','A10-A62','A62-A10','A89-A63', 'A63-A89' ]]))


get_ipython().run_line_magic("time", " df_transit_extrapole=corr.predire_ts_trajets(df_transit_marge0_ss_extrapolation)")


alt.vconcat(g.graph_transit_filtre_multiple(df_transit_marge0_ss_extrapolation,'2019-01-23 00:00:00', '2019-01-23 23:59:59','A89-A660', 1),
g.graph_transit_filtre_multiple(df_transit_extrapole,'2019-01-23 00:00:00', '2019-01-23 23:59:59','A89-A660', 1)) 


get_ipython().run_line_magic("time", " df_transit_extrapole_tps_filtre_modif, dixco_tpsmax_corrige=corr.corriger_tps_parcours_extrapole(dixco_tpsmax_corrige,df_transit_extrapole)")


#creation des attributs relatifs a Cestas, pour les PL sur une O-D liées à A63, non identifiés comme transit, et qui ont été vus à Cestas
get_ipython().run_line_magic("time", " df_transit_A63_redresse=corr.correction_temps_cestas(df_transit_extrapole_tps_filtre_modif,df_passages_immat_ok,dixco_tpsmax_corrige)")


#graph
alt.vconcat(g.graph_transit_filtre(df_transit_marge0_ss_extrapolation,'2019-02-07 00:00:00', '2019-02-07 23:59:59','A63-N10'),
g.graph_transit_filtre(test,'2019-02-07 00:00:00', '2019-02-07 23:59:59','A63-N10'))


get_ipython().run_line_magic("time", " dico_transit_ss_marge=transit.transit_marge0(df_transit_extrapole_tps_filtre_modif,df_transit_A63_redresse)")


r.save_donnees(dico_transit_ss_marge['df_transit_airesA63_ss_filtre'], 
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\df_marge0\df_transit_airesA63_ss_filtre.json')
r.save_donnees(dico_transit_ss_marge['df_transit_airesA63_avec_filtre'], 
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\df_marge0\df_transit_airesA63_avec_filtre.json')
r.save_donnees(dico_transit_ss_marge['df_transit_pas_airesA63_ss_filtre'], 
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\df_marge0\df_transit_pas_airesA63_ss_filtre.json')
r.save_donnees(dico_transit_ss_marge['df_transit_marge0_ss_filtre'], 
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\df_marge0\df_transit_marge0_ss_filtre.json')
r.save_donnees(dico_transit_ss_marge['df_transit_marge0_avec_filtre'], 
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\df_marge0\df_transit_marge0_avec_filtre.json')


alt.vconcat(g.graph_transit_filtre(dico_transit_ss_marge['df_transit_marge0_ss_filtre'],'2019-02-07 00:00:00', '2019-02-07 23:59:59','A63-N10'),
            g.graph_transit_filtre(total,'2019-02-07 00:00:00', '2019-02-07 23:59:59','A63-N10'))


get_ipython().run_line_magic("time", " dico_transit_avec_marge=tc.appliquer_marge([45,60,90,120],dico_transit_ss_marge['df_transit_airesA63_avec_filtre'],dico_transit_ss_marge['df_transit_pas_airesA63_ss_filtre'])")


r.save_donnees(dico_transit_avec_marge['df_transit_marge45_avec_filtre'], 
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\df_marges\df_transit_marge45_avec_filtre.json')
r.save_donnees(dico_transit_avec_marge['df_transit_marge60_avec_filtre'], 
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\df_marges\df_transit_marge60_avec_filtre.json')
r.save_donnees(dico_transit_avec_marge['df_transit_marge90_avec_filtre'], 
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\df_marges\df_transit_marge90_avec_filtre.json')
r.save_donnees(dico_transit_avec_marge['df_transit_marge120_avec_filtre'], 
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\df_marges\df_transit_marge120_avec_filtre.json')


get_ipython().run_line_magic("time", " dico_corr_A63_A660=tc.correction_A660(dico_transit_avec_marge,df_passages_immat_ok,[45,60,90,120])")


r.save_donnees(dico_corr_A63_A660['corr_A63_A66045'], 
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\df_corrA660A63\corr_A63_A66045.json')
r.save_donnees(dico_corr_A63_A660['corr_A63_A66060'], 
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\df_corrA660A63\corr_A63_A66060.json')
r.save_donnees(dico_corr_A63_A660['corr_A63_A66090'], 
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\df_corrA660A63\corr_A63_A66090.json')
r.save_donnees(dico_corr_A63_A660['corr_A63_A660120'], 
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Traitements\python\donnees_sources\df_corrA660A63\corr_A63_A660120.json')


get_ipython().run_line_magic("time", " dico_df_od_final=tc.extrapol_trajets_incomplets(dico_transit_avec_marge,df_passages_immat_ok,dico_corr_A63_A660,[45,60], dixco_tpsmax_corrige)")


#resultats
r.save_donnees(dico_df_od_final['df_od_final_marge45'],
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Projet Rapport\resultats\df_od_final_marge45.json')
r.save_donnees(dico_df_od_final['df_od_final_marge60'],
               r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Projet Rapport\resultats\df_od_final_marge60.json')



get_ipython().run_line_magic("time", " df_transit_propre, df_filtree = r.filtrer_jour_non_complet(dico_df_od_final['df_od_final_marge60'])")


get_ipython().run_line_magic("time", " df_transit, df_avant31, df_apres31 = r.decoupe_df_avant_apres_31(df_transit_propre)")


r.matrice_transit(r.df_transit_propre_jo(df_apres31), type_j='jo_sup_31')


r.matrice_transit(r.df_transit_propre_jo(df_avant31),type_j='jo_inf_31')


r.matrice_transit(r.df_transit_propre_jo(df_transit),type_j='jo')


get_ipython().run_cell_magic("time", " ", """#variables
mat_df_transit_marge0_ss_extrapolation=r.matrice_transit(r.df_transit_propre_jo(r.decoupe_df_avant_apres_31(r.filtrer_jour_non_complet(
    df_transit_marge0_ss_extrapolation.loc[df_transit_marge0_ss_extrapolation['filtre_tps']==1])[0])[2]),'jo_sup_31')""")


mat_df_transit_marge0_ss_extrapolation


mat_df_transit_extrapole=r.matrice_transit(r.df_transit_propre_jo(r.decoupe_df_avant_apres_31(r.filtrer_jour_non_complet(
    df_transit_extrapole.loc[df_transit_extrapole['filtre_tps']==1])[0])[2]),'jo_sup_31')
mat_df_transit_extrapole


mat_dico_transit_ss_marge=r.matrice_transit(r.df_transit_propre_jo(r.decoupe_df_avant_apres_31(r.filtrer_jour_non_complet(
    dico_transit_ss_marge['df_transit_marge0_avec_filtre'])[0])[2]),'jo_sup_31')


mat_dico_transit_ss_marge


mat_dico_transit_avec_marge=r.matrice_transit(r.df_transit_propre_jo(r.decoupe_df_avant_apres_31(r.filtrer_jour_non_complet(
    dico_transit_avec_marge['df_transit_marge60_avec_filtre'])[0])[2]),'jo_sup_31')


mat_dico_transit_avec_marge


mat_dico_corr_A63_A660=r.matrice_transit(r.df_transit_propre_jo(r.decoupe_df_avant_apres_31(r.filtrer_jour_non_complet(
    dico_corr_A63_A660['corr_A63_A66060'])[0])[2]),'jo_sup_31')


mat_dico_corr_A63_A660


mat_dico_df_od_final=r.matrice_transit(r.df_transit_propre_jo(r.decoupe_df_avant_apres_31(r.filtrer_jour_non_complet(
    dico_df_od_final['df_od_final_marge60'])[0])[2]),'jo_sup_31')


mat_dico_df_od_final


((mat_df_transit_extrapole /  mat_df_transit_marge0_ss_extrapolation)-1)*100


mat_df_transit_extrapole -  mat_df_transit_marge0_ss_extrapolation


((mat_dico_transit_ss_marge/mat_df_transit_extrapole)-1)*100


mat_dico_transit_ss_marge-mat_df_transit_extrapole


#pour rappel, marg ede 60 minutes uniquement pour PL depuis ou vers A63, non vu à Cestas. pour le reste : 15 min
((mat_dico_transit_avec_marge/mat_dico_transit_ss_marge)-1)*100


mat_dico_transit_avec_marge-mat_dico_transit_ss_marge


((mat_dico_corr_A63_A660/mat_dico_transit_avec_marge)-1)*100


mat_dico_corr_A63_A660-mat_dico_transit_avec_marge


((mat_dico_df_od_final/mat_dico_corr_A63_A660)-1)*100


mat_dico_df_od_final-mat_dico_corr_A63_A660


# passages et passages de transit apres le 31/01 en JO
df_apres31_jo = r.df_transit_propre_jo(df_apres31)
df_passages_apres_31 = df_passages_immat_ok.loc[(df_passages_immat_ok.index >= pd.to_datetime('2019-01-31')) & (df_passages_immat_ok.index.dayofweek<5)]
passages_transit_apres_31 = trajets.trajet2passage(df_apres31_jo, df_passages_apres_31)

# determiner les passages fictifs Rocade
df_passage_transit_redresse_31, df_pl_redresse_31, trajets_rocade_non_vu_31 = r.passages_fictif_rocade(
    i_f.liste_trajet_rocade, df_apres31_jo, passages_transit_apres_31, df_passages_apres_31)
# passages fictifs correction A660-A63 et trajets incomplets
passage_transit_redress_31, passages_tot_redresse_31 = r.passage_fictif_od(df_apres31_jo, df_passage_transit_redresse_31, df_pl_redresse_31)
# regrouper
df_concat_pl_jo_31, df_pct_pl_transit_31 = r.pourcentage_pl_camera(passages_tot_redresse_31, passage_transit_redress_31)
# ajouter n10
# df_concat_pl_jo_31, df_pct_pl_transit_31 = r.ajout_cam_n10(df_concat_pl_jo_31, df_pct_pl_transit_31)


g.intervalle_confiance_cam(df_pct_pl_transit_31,df_concat_pl_jo_31,True,11,12)[0]


g.intervalle_confiance_cam(df_pct_pl_transit_31,df_concat_pl_jo_31,True,3,4)[1]


# pour info
concat_dir_trafic, df_pct_pl_transit_multi_cam=r.PL_transit_dir_jo_cam(df_pct_pl_transit_31,[8])
concat_dir_trafic.loc[concat_dir_trafic['type']=='PL en transit']


g.graph_PL_transit_dir_jo_cam(df_pct_pl_transit_31,3,4)


for i in [6,10,15, 8] : 
    fichier=f'nb_pl_transit_cam{i}.svg'
    g.graph_PL_transit_dir_jo_cam(df_pct_pl_transit_31,i).save(
    os.path.join(r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Projet Rapport\illustrations\rapport\nb_pl_transit',fichier))


g.graph_TV_jo_cam(df_pct_pl_transit_31,False,0,3,4)


sankey_rocade_f_s_n, sankey_rocade_f_n_s, sankey_direct_tot, df_sankey=r.donnees_sankey(df_apres31)


g.sankey(sankey_rocade_f_s_n, 'Flux o-d selon la Rocade').show(renderer='svg')
#.write_image(r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Projet Rapport\illustrations\sankey_rocade_n_s.png')


g.sankey(df_sankey, 'Flux o-d').show(renderer='svg')


synthes_nb_veh=r.nb_pl_reel_par_site_mjo(df_pct_pl_transit_31)[0]
synthes_nb_veh.to_csv(r'Q:\DAIT\TI\DREAL33\2018\C17SI0073_LAPI\Projet Rapport\qgis\synthese_resultats.csv')


# ouvertur des donnees de passages total et de passages transit et recherche des states inconu et de leur part : environ 5%
pctStateNcTotal = len(passages_tot_redresse_31.loc[passages_tot_redresse_31.state.apply(lambda x: x == '  ' or '/' in x)])/len(passages_tot_redresse_31)
pctStateNcTransit = len(passage_transit_redress_31.loc[passage_transit_redress_31.state.apply(lambda x: x == '  ' or '/' in x)])/len(passage_transit_redress_31)
# mettre à jour les denomination d'Etat si inconnu ou hesitation de la part de l'identification Mac
passages_tot_redresse_31['state_modif_nc'] = passages_tot_redresse_31.state.apply(lambda x: n.modifStateInconnu(x))
passage_transit_redress_31['state_modif_nc'] = passage_transit_redress_31.state.apply(lambda x: n.modifStateInconnu(x))
# mettre a jour un attribut qui classe en français / etranger
passages_tot_redresse_31['state_fr_etr'] = passages_tot_redresse_31.state.apply(lambda x: n.modifStateFrAutre(x))
passage_transit_redress_31['state_fr_etr'] = passage_transit_redress_31.state.apply(lambda x: n.modifStateFrAutre(x))


# pour info, exemple de plque mal lue
passages_tot_redresse_31.loc[(passages_tot_redresse_31.state_modif_nc == 'nc') & 
                             (passages_tot_redresse_31.fiability != 999) & 
                             (passages_tot_redresse_31.fiability.notna()) & 
                             (passages_tot_redresse_31.state != '  ') & 
                             (passages_tot_redresse_31.state.apply(lambda x: 'FR' not in x))].drop_duplicates('state')[[
    'immat', 'camera_id', 'fiability', 'state']]


(df10PaysPlusRepresenteTransit, df10PaysPlusRepresenteGlobal,
 df6ZonesPlusRepresenteGlobal, df6ZonesPlusRepresenteTransit) = n.creerDataGroupeNationalite(passages_tot_redresse_31, passage_transit_redress_31)


(chartRepartitionGlobalPaysGeneral, chartRepartitionTransitPaysGeneral,
 chartRepartitionGlobalZoneGeneral, chartRepartitionTransitZoneGeneral) = g.graphNationalitePartGenerale(df10PaysPlusRepresenteTransit, df10PaysPlusRepresenteGlobal,
                                                                                                         df6ZonesPlusRepresenteGlobal, df6ZonesPlusRepresenteTransit)


chartRepartitionGlobalPaysGeneral | chartRepartitionTransitPaysGeneral


chartRepartitionGlobalZoneGeneral | chartRepartitionTransitZoneGeneral


# part des 10 nationalités les plus représentées par rapport au global
pct10NatPrincipaleGlobale, pct10NatPrincipaleTransit = n.partXNationalite(passages_tot_redresse_31, 10), n.partXNationalite(passage_transit_redress_31, 10)
pct5NatPrincipaleGlobale, pct5NatPrincipaleTransit = n.partXNationalite(passages_tot_redresse_31, 5), n.partXNationalite(passage_transit_redress_31, 5)
pct3NatPrincipaleGlobale, pct3NatPrincipaleTransit = n.partXNationalite(passages_tot_redresse_31, 3), n.partXNationalite(passage_transit_redress_31, 3)
(pct10NatPrincipaleGlobale, pct10NatPrincipaleTransit, pct5NatPrincipaleGlobale, pct5NatPrincipaleTransit,
 pct3NatPrincipaleGlobale, pct3NatPrincipaleTransit,
 len(passages_tot_redresse_31.loc[passages_tot_redresse_31.state_modif_nc == 'nc']) / len(passages_tot_redresse_31))


df_concat_pl_jo, df_concat_pl_joMoy = n.creerDataGraphsHorairesMoyens(passages_tot_redresse_31, passage_transit_redress_31)


# partie export
dossierExport = r'C:\Users\martin.schoreisz\Box\Dossier_Perso\LAPI\graphsRepartitionFrEtranger_parSite'
for k, v in i_f.dico_corrsp_camera_site.items():
    print(k, v)
    g.graphNationaliteRepartitionFrEtranger(v, k, df_concat_pl_joMoy).save(os.path.join(dossierExport, f"{k.replace('/', '-')}.svg"))


# exemple de visu
g.graphNationaliteRepartitionFrEtranger([20, 21], 'Rocade Est', df_concat_pl_joMoy)


# partie export
dossierExport = r'C:\Users\martin.schoreisz\Box\Dossier_Perso\LAPI\graphRepartitionLocalTransit_parSite'
for k, v in i_f.dico_corrsp_camera_site.items():
    print(k, v)
    g.graphNationaliteTransitLocal(v, k, df_concat_pl_joMoy).save(os.path.join(dossierExport, f"{k.replace('/', '-')}.svg"))


listCamera = [3, 4]
g.graphNationaliteTransitLocal(listCamera, 'N10', df_concat_pl_joMoy)


dfDatasSaved = pd.read_csv(r'C:\Users\martin.schoreisz\Box\Cerema\60-SO\66-DM\6615-PMD\080-Dossiers\LAPI\C17SI0073_LAPI\Nationalites\Datas\Nationalite_transit_ou_total_MJO.csv')


dfDatasSavedGroupedNomCols = dfDatasSavedGrouped.pivot(index='camera_id', columns=['state_fr_etr', 'type'], values='nb_veh').reset_index().set_index('camera_id')
dfDatasSavedGroupedNomCols = dfDatasSavedGroupedNomCols.reset_index().T.reset_index().T.drop(['state_fr_etr', 'type']).rename(
    columns={0: 'camera_id', 1: 'PL total étranger', 2: 'PL transit étranger', 3: 'PL total français', 4: 'PL transit français'})
dfDatasSavedGroupedNomCols = dfDatasSavedGroupedNomCols.assign(
    camNom=dfDatasSavedGroupedNomCols.camera_id.replace({v[0]: k for k, v in i_f.dico_corrsp_camera_site.items() if len(v) ==1}),
    PL_local_français=dfDatasSavedGroupedNomCols['PL total français'] - dfDatasSavedGroupedNomCols['PL transit français'],
    PL_local_etranger=dfDatasSavedGroupedNomCols['PL total étranger'] - dfDatasSavedGroupedNomCols['PL transit étranger'])


dfDatasSavedGroupedNomCols.replace({'A660': 'A660/A63', 'N89': 'A89'}, regex=True).to_csv(
    r'C:\Users\martin.schoreisz\Box\Cerema\60-SO\66-DM\6615-PMD\080-Dossiers\LAPI\C17SI0073_LAPI\Nationalites\Datas\jourmoyen-graph_camembert.csv')


dfDataCamembertQgis = pd.read_csv(
    r'C:\Users\martin.schoreisz\Box\Cerema\60-SO\66-DM\6615-PMD\080-Dossiers\LAPI\C17SI0073_LAPI\Nationalites\Datas\jourmoyen-graph_camembert.csv')
# partie export
dossierExport = r'C:\Users\martin.schoreisz\Box\Cerema\60-SO\66-DM\6615-PMD\080-Dossiers\LAPI\C17SI0073_LAPI\Nationalites\graphsRepartitionFrancaisEtrangersJourSite'
for k, v in i_f.dico_corrsp_camera_site.items():
    print(k, v)
    g.graphNationaliteTransitLocalJour(dfDataCamembertQgis, v, k).save(os.path.join(dossierExport, f"{k.replace('/', '-')}.svg"))


dfDataCamembertQgis


# paramètres
date_debut = '2019-01-22 00:00:00'
nb_jours = 23
listeTrajetPendulaireA63Complet = (pd.DataFrame({'cam_d': [13, 13, 13, 13],
                                                 'cam_o': [15, 15, 15, 15],
                                                 'cameras': ((15, 19, 18, 13), (15, 19, 13), (15, 18, 13), (15, 13)),
                                                 'origine': ['A63', 'A63', 'A63', 'A63'],
                                                 'destination': ['A63', 'A63', 'A63', 'A63'],
                                                 'long_km': [1, 1, 1, 1],
                                                 'nb_cams': [4, 3, 3, 2],
                                                 'o_d': ['A63-A63', 'A63-A63', 'A63-A63', 'A63-A63'],
                                                 'tps_parcours_theoriq': [pd.Timedelta(hours=1),
                                                                          pd.Timedelta(hours=1),
                                                                          pd.Timedelta(hours=1),
                                                                          pd.Timedelta(hours=1)]}))
listeTrajetPendulaireA63Incomplet = (pd.DataFrame({'cam_d': [13, 13, 18, 18],
                                                   'cam_o': [19, 19, 15, 15],
                                                   'cameras': ((19, 18, 13), (19, 13), (15, 19, 18), (15, 18)),
                                                   'origine': ['A660', 'A660', 'A63', 'A63'],
                                                   'destination': ['A63', 'A63', 'A660', 'A660'],
                                                   'long_km': [1, 1, 1, 1],
                                                   'nb_cams': [3, 2, 3, 2],
                                                   'o_d': ['A660-A63', 'A660-A63', 'A63-A660', 'A63-A660'],
                                                   'tps_parcours_theoriq': [pd.Timedelta(hours=1),
                                                                            pd.Timedelta(hours=1),
                                                                            pd.Timedelta(hours=1),
                                                                            pd.Timedelta(hours=1)]}))
listeTrajetPendulaireA63 = pd.concat([listeTrajetPendulaireA63Complet, listeTrajetPendulaireA63Incomplet])


# base : df des passages non concernés par du transit
passageNonTransit = passages_tot_redresse_31.loc[
    ~passages_tot_redresse_31.reset_index().set_index(['created', 'camera_id', 'immat']).index.isin(
        passage_transit_redress_31.set_index(['created', 'camera_id', 'immat']).index.tolist())].copy()


# calcul des trajets complets (avec début et fin connu)
dico_od,  dico_passag, dico_tps_max = transit.transit_temps_complet('2019-01-22 00:00:00', 23, passageNonTransit, listeTrajetPendulaireA63)


# pour les trajets non cpaté au péage de A63, on sépare en 4 cas : on ne garde que les 1 et 2 (i.e le PL est vu avant ou après au péage)
# car les cas 3 et 4 représente des PL qui ne font que passer aux 18 et 19, sans passer au péage
dico_od_corrige = corr.correction_trajet(passageNonTransit, dico_od, voie_ref='A660', cam_ref_1=13, cam_ref_2=15, cam_ref_3=19)
dico_od_corrige = dico_od_corrige.loc[(~dico_od_corrige.correction_o_d_type.isin(('correction_A63_cas3', 'correction_A63_cas4'))) | 
                     (dico_od_corrige.correction_o_d.isna())].copy()
# on ramène ça sur des passages
dfPassagesPendulaire = trajets.trajet2passage(dico_od_corrige, passageNonTransit)
# on ajoute les passages fictifs
passagePendulaireRedress, passagesPendulaireTotRedresse = r.passage_fictif_od(dico_od_corrige, dfPassagesPendulaire, passageNonTransit)


# et on isole les résultats au péage sens Sud-Nord, pour les 3 principaux cas
dfPassagesPendulaireA63SN = passagePendulaireRedress.loc[passagePendulaireRedress.camera_id == 15].copy()
dfpassageHorsTransitTotA63SN = passagesPendulaireTotRedresse.loc[passagesPendulaireTotRedresse.camera_id == 15].copy()
dfpassageTotA63SN = pd.concat([passage_transit_redress_31.loc[passage_transit_redress_31.camera_id == 15].set_index('created'), dfpassageHorsTransitTotA63SN])


# mis en forme pour graphs
df_concat_pl_jo_HorsTransitPendul, df_pct_pl_HorsTransitPendul = r.pourcentage_pl_camera(dfpassageHorsTransitTotA63SN, dfPassagesPendulaireA63SN)
df_concat_pl_jo_tousPLPendul, df_pct_pl_tousPLPendul = r.pourcentage_pl_camera(dfpassageTotA63SN, dfPassagesPendulaireA63SN)
df_pct_pl_HorsTransitPendul.replace({'PL total' : 'PL hors transit', 'PL transit': 'PL pendulaire'}, inplace=True)
df_concat_pl_jo_HorsTransitPendul.type.replace({'PL total' : 'PL hors transit', 'PL transit': 'PL pendulaire'}, inplace=True)
df_pct_pl_tousPLPendul.replace({'PL transit': 'PL pendulaire'}, inplace=True)
df_concat_pl_jo_tousPLPendul.type.replace({'PL total' : 'PL hors transit', 'PL transit': 'PL pendulaire'}, inplace=True)
df_pct_pl_HorsTransitPendul.rename(columns={'pct_pl_transit': 'pct_pl_pendul'}, inplace=True)
df_pct_pl_tousPLPendul.rename(columns={'pct_pl_transit': 'pct_pl_pendul'}, inplace=True)


dicoCouleur = {'PL pendulaire': '#4c78a8', 'PL hors transit': '#f58518', 'Tous PL':'#e45756', 'PL hors transit_atteignant la rocade': '#b79a20',
               'PL en transit': '#54a24b', 'PL pendulaire vu_uniquement au péage': '#6baed6', 'PL pendulaire vu_à Cestas': '#c6dbef'}
dicoCouleurKeys, dicoCouleurValues = [e for e in dicoCouleur.keys()], [e for e in dicoCouleur.values()]


# graphe PL penduiare par rapport au trafic hors transit
dfConcatTypePl = pd.melt(df_pct_pl_HorsTransitPendul, id_vars=['heure', ],
                         value_vars=['nb_veh_x', 'nb_veh_y'], var_name='type', value_name='nb_pl'
                         ).replace({'nb_veh_x': 'PL hors transit', 'nb_veh_y': 'PL pendulaire'})
titre = alt.TitleParams("Volume et part de PL pendulaires n'atteignant pas la rocade",
                        fontSize=18,
                        subtitle=['Péage A63 Saugnacq-et-Muret ; sens Sud -> Nord ; Jour ouvré moyen'],
                        subtitleFontSize=14)
bar_nb_pl_dir = alt.Chart(dfConcatTypePl, title=titre).mark_bar(opacity=0.9).encode(
    x=alt.X('heure:O',axis=alt.Axis(title='Heure',titleFontSize=14,labelFontSize=14)),
    y=alt.Y('nb_pl:Q',stack=None, axis=alt.Axis(title='Nombre de PL',titleFontSize=14,labelFontSize=14)),
    color=alt.Color('type:N',legend=alt.Legend(title='Type de PL',titleFontSize=14,labelFontSize=14, values=dicoCouleurKeys[:2]),sort="descending",
                    scale=alt.Scale(domain=dicoCouleurKeys, range=dicoCouleurValues)))
line_pct_pl_lapi = alt.Chart(df_pct_pl_HorsTransitPendul).mark_line(color='green').encode(
    x=alt.X('heure:O',axis=alt.Axis(title='Heure',titleFontSize=14,labelFontSize=14)),
    y=alt.Y('pct_pl_pendul', axis=alt.Axis(title='% PL pendulaire',labelFontSize=14,labelColor='green',titleFontSize=14,titleColor='green',grid=False),
            scale=alt.Scale(domain=(0,100))))
(bar_nb_pl_dir+line_pct_pl_lapi).resolve_scale(y='independent').properties(width=600, height=300).configure_title(fontSize=18)


# graph tous PL 
dfConcatTypePl = pd.melt(df_pct_pl_tousPLPendul.merge(df_pct_pl_HorsTransitPendul[['heure', 'nb_veh_x']], on='heure', suffixes=['_tousPL', '_transit']),
                         id_vars='heure', value_vars=['nb_veh_x_tousPL', 'nb_veh_y', 'nb_veh_x_transit'], var_name='type', value_name='nb_pl'
                        ).replace({'nb_veh_x_tousPL': 'Tous PL', 'nb_veh_y': 'PL pendulaire', 'nb_veh_x_transit': 'PL hors transit'})
dfConcatTypePl['ordre_stack']=dfConcatTypePl['type'].replace({'PL pendulaire': 3, 'PL hors transit': 2, 'Tous PL': 1})
dfNorm = (df_pct_pl_tousPLPendul.merge(df_pct_pl_HorsTransitPendul[['heure', 'nb_veh_x']], on='heure', suffixes=['_tousPL', '_transit'])
              .rename(columns={'nb_veh_x_transit': 'nb_veh_x_hors_transit', 'nb_veh_y': 'nb_veh_pendul'}))
dfNorm['nb_veh_x_transit'] = dfNorm.nb_veh_x_tousPL - dfNorm.nb_veh_x_hors_transit
dfNorm['nb_veh_HorsTransit_atteintRocade'] = dfNorm.nb_veh_x_hors_transit - dfNorm.nb_veh_pendul
dfNorm = dfNorm.melt(id_vars='heure', value_vars=['nb_veh_x_transit', 'nb_veh_HorsTransit_atteintRocade', 'nb_veh_pendul'], var_name='type', value_name='nb_pl'
            ).replace({'nb_veh_x_transit': 'PL en transit', 'nb_veh_pendul': 'PL pendulaire',
                       'nb_veh_HorsTransit_atteintRocade': 'PL hors transit_atteignant la rocade'})
dfNorm['ordre_norm'] = dfNorm['type'].replace({'PL pendulaire': 1, 'PL hors transit_atteignant la rocade': 2, 'PL en transit': 3})
filtreLegendNorm = dfNorm.type.unique()
filtreLegendStack = dfConcatTypePl.type.unique()
titreStack = alt.TitleParams("Volume et part de PL pendulaire n'atteignant pas la rocade",
                             anchor='middle',
                             fontSize=18,
                             subtitle=['Péage A63 Saugnacq-et-Muret ; sens Sud -> Nord ; Jour ouvré moyen'],
                             subtitleFontSize=14)
bar_nb_pl_dir=alt.Chart(dfConcatTypePl).mark_bar().encode(
    x=alt.X('heure:O',axis=alt.Axis(title='Heure',titleFontSize=14,labelFontSize=14)),
    y=alt.Y('nb_pl:Q',stack=None, axis=alt.Axis(title='Nombre de PL',titleFontSize=14,labelFontSize=14)),
    color=alt.Color('type:N',legend=alt.Legend(title='Type de PL',titleFontSize=14,labelFontSize=14, values=filtreLegendStack),sort="descending",
                    scale=alt.Scale(domain=dicoCouleurKeys, range=dicoCouleurValues)),
    order='ordre_stack')
stack_bar_nb_pl_dir=alt.Chart(dfNorm).mark_bar().encode(
    x=alt.X('heure:O',axis=alt.Axis(title='Heure',titleFontSize=14,labelFontSize=14)),
    y=alt.Y('nb_pl:Q',stack='normalize', axis=alt.Axis(title='Part de PL',titleFontSize=14,labelFontSize=14, format='%')),
    color=alt.Color('type:N', legend=alt.Legend(title='Type de PL',titleFontSize=14,labelFontSize=14, 
                                                values=filtreLegendNorm, labelExpr="split(datum.value, '_')"),sort="descending",
                    scale=alt.Scale(domain=dicoCouleurKeys, range=dicoCouleurValues)),
    order='ordre_norm')
(bar_nb_pl_dir & stack_bar_nb_pl_dir).resolve_scale(color='independent').properties(title=titreStack)


# graphs des heures de pointes
dfDiagCirc = df_pct_pl_tousPLPendul.merge(df_pct_pl_HorsTransitPendul[['heure', 'nb_veh_x']], on='heure', suffixes=['_tousPL', '_transit'])
dfDiagCirc['PL en transit'] = dfDiagCirc.nb_veh_x_tousPL - dfDiagCirc.nb_veh_x_transit
dfDiagCirc['PL hors transit_atteignant la rocade'] = dfDiagCirc.nb_veh_x_transit - dfDiagCirc.nb_veh_y
dfDiagCirc.drop(['type_x', 'type_y', 'pct_pl_pendul', 'legend', 'nb_veh_x_transit', 'nb_veh_x_tousPL'], axis=1, errors='ignore', inplace=True)
dfDiagCirc = dfDiagCirc.melt(id_vars='heure', value_vars=['nb_veh_y', 'PL en transit', 'PL hors transit_atteignant la rocade'],
                             value_name='nb_pl', var_name='type').replace({'nb_veh_y': 'PL pendulaire'})

dfDiagCircHpm = dfDiagCirc.loc[dfDiagCirc.heure.isin((6, 7, 8))].groupby('type')['nb_pl'].mean().reset_index()
dfDiagCircHps = dfDiagCirc.loc[dfDiagCirc.heure.isin((16, 17, 18))].groupby('type')['nb_pl'].mean().reset_index()
dfDiagCircHpm['nb_pl'] = dfDiagCircHpm['nb_pl'].astype(int)
dfDiagCircHps['nb_pl'] = dfDiagCircHps['nb_pl'].astype(int)

hauteur, largeur = 250, 400
filtreLegende = dfDiagCircHps.type.unique()
titreHPM = alt.TitleParams(["Répartition horaire des PL ;", "heure de pointe du matin (6h - 9h)"],
                             anchor='middle',
                             align='center',
                             fontSize=16,
                             subtitle=['Péage A63 Saugnacq-et-Muret ; sens Sud -> Nord ; Jour ouvré moyen'],
                             subtitleFontSize=13)
titreHPS = alt.TitleParams(["Répartition horaire des PL ;", "heure de pointe du soir (16h - 19h)"],
                             anchor='middle',
                             align='center',
                             fontSize=16,
                             subtitle=['Péage A63 Saugnacq-et-Muret ; sens Sud -> Nord ; Jour ouvré moyen'],
                             subtitleFontSize=13)
baseHpm = alt.Chart(dfDiagCircHpm, title=titreHPM, width=largeur, height=hauteur).encode(
    theta=alt.Theta("nb_pl:Q", stack=True),
    radius=alt.Radius("nb_pl", scale=alt.Scale(type="sqrt", zero=True, rangeMin=20)),
    color=alt.Color("type:N", title='Type de PL', scale=alt.Scale(domain=dicoCouleurKeys, range=dicoCouleurValues),
                    legend=alt.Legend(values=filtreLegende, labelExpr="split(datum.value, '_')")))
c1Hpm = baseHpm.mark_arc(innerRadius=20, stroke="#fff")
c2Hpm = baseHpm.mark_text(radiusOffset=10).encode(text="nb_pl:Q")
baseHps = alt.Chart(dfDiagCircHps, title=titreHPS, width=largeur, height=hauteur).encode(
    theta=alt.Theta("nb_pl:Q", stack=True),
    radius=alt.Radius("nb_pl", scale=alt.Scale(type="sqrt", zero=True, rangeMin=20)),
    color=alt.Color("type:N", title='Type de PL', scale=alt.Scale(domain=dicoCouleurKeys, range=dicoCouleurValues),
                    legend=alt.Legend(values=filtreLegende, labelExpr="split(datum.value, '_')")))
c1Hps = baseHps.mark_arc(innerRadius=20, stroke="#fff")
c2Hps = baseHps.mark_text(radiusOffset=10).encode(text="nb_pl:Q")
(c1Hpm + c2Hpm).configure_legend(titleFontSize=14, labelFontSize=14)


(c1Hps + c2Hps).configure_legend(titleFontSize=14, labelFontSize=14)


# on isole les résultats au péage sens Sud-Nord, pour les 3 principaux cas
dfPassagesPendulaireCestasSN = passagePendulaireRedress.loc[passagePendulaireRedress.camera_id == 19].copy()
df_pl,dico_passag = dfPassagesPendulaireA63SN.set_index('created').copy(), dfPassagesPendulaireCestasSN.copy()

def pct_pl(a,b):
    try :
        return round(a*100/b)
    except ZeroDivisionError : 
        return 0


df_synthese_pl_tot=df_pl.groupby('camera_id').resample('H').count()['immat'].reset_index().rename(columns={'immat':'nb_veh'})
df_synthese_pl_transit=dico_passag.set_index('created').groupby('camera_id').resample('H').count()['immat'].reset_index().rename(
        columns={'immat':'nb_veh'})
df_synthese_pl_tot['heure']=df_synthese_pl_tot.created.dt.hour
df_synthese_pl_transit['heure']=df_synthese_pl_transit.created.dt.hour
df_synthese_pl_tot['type']='PL total'
df_synthese_pl_transit['type']='PL transit'
df_concat_pl=pd.concat([df_synthese_pl_tot,df_synthese_pl_transit],sort=False)
df_concat_pl_jo=df_concat_pl.loc[df_concat_pl.set_index('created').index.dayofweek < 5].copy()
df_concat_pl_jo=df_concat_pl_jo.groupby(['camera_id', 'type','heure']).mean().reset_index()
df_pct_pl_transit=df_concat_pl_jo.loc[df_concat_pl_jo['type']=='PL total'].merge(df_concat_pl_jo.loc[df_concat_pl_jo['type']=='PL transit'],on=['heure'])
df_pct_pl_transit['pct_pl_transit']=df_pct_pl_transit.apply(lambda x : pct_pl(x['nb_veh_y'],x['nb_veh_x']) ,axis=1)
df_pct_pl_transit.replace({'PL transit': 'PL pendulaire vu à Cestas'}, inplace=True)
df_pct_pl_transit['nb_veh_ar_peage'] = round(df_pct_pl_transit.nb_veh_x - df_pct_pl_transit.nb_veh_y)


hauteur, largeur = 250, 400
dfGraphCircCestas = (df_pct_pl_transit
                     .melt(id_vars='heure', value_vars=['nb_veh_ar_peage', 'nb_veh_y'], var_name='type', value_name='nb_pl')
                     .replace({'nb_veh_ar_peage': 'PL pendulaire vu_uniquement au péage', 'nb_veh_y': 'PL pendulaire vu_à Cestas'}))
dfGraphCircCestasHps = dfGraphCircCestas.loc[dfGraphCircCestas.heure.isin((16, 17, 18))].groupby('type')['nb_pl'].mean().reset_index()
dfGraphCircCestasHps['nb_pl'] = dfGraphCircCestasHps['nb_pl'].astype(int)
dfGraphCircCestasHpm = dfGraphCircCestas.loc[dfGraphCircCestas.heure.isin((6, 7, 8))].groupby('type')['nb_pl'].mean().reset_index()
dfGraphCircCestasHpm['nb_pl'] = dfGraphCircCestasHpm['nb_pl'].astype(int)
filtreLegendeCestas = dfGraphCircCestasHpm.type.unique()
titreCestasHpm = alt.TitleParams(["Répartition horaire des PL pendulaires ;", "heure de pointe du matin (6h - 9h)"],
                             anchor='middle',
                             align='center',
                             fontSize=16,
                             subtitle=['Péage A63 Saugnacq-et-Muret ; sens Sud -> Nord ; Jour ouvré moyen'],
                             subtitleFontSize=13)
titreCestasHps = alt.TitleParams(["Répartition horaire des PL pendulaires ;", "heure de pointe du soir (16h - 19h)"],
                             anchor='middle',
                             align='center',
                             fontSize=16,
                             subtitle=['Péage A63 Saugnacq-et-Muret ; sens Sud -> Nord ; Jour ouvré moyen'],
                             subtitleFontSize=13)
baseCestasHpm = alt.Chart(dfGraphCircCestasHpm, title=titreCestasHpm, width=largeur, height=hauteur).encode(
    theta=alt.Theta("nb_pl:Q", stack=True),
    radius=alt.Radius("nb_pl", scale=alt.Scale(type="sqrt", zero=True, rangeMin=20)),
    color=alt.Color("type:N", title='Type de PL', scale=alt.Scale(domain=dicoCouleurKeys, range=dicoCouleurValues),
                    legend=alt.Legend(values=filtreLegendeCestas, labelLimit=-1, labelExpr="split(datum.value, '_')")))
baseCestasHps = alt.Chart(dfGraphCircCestasHps, title=titreCestasHps, width=largeur, height=hauteur).encode(
    theta=alt.Theta("nb_pl:Q", stack=True),
    radius=alt.Radius("nb_pl", scale=alt.Scale(type="sqrt", zero=True, rangeMin=20)),
    color=alt.Color("type:N", title='Type de PL', scale=alt.Scale(domain=dicoCouleurKeys, range=dicoCouleurValues),
                    legend=alt.Legend(values=filtreLegendeCestas, labelLimit=-1, labelExpr="split(datum.value, '_')")))
c1CestasHpm = baseCestasHpm.mark_arc(innerRadius=20, stroke="#fff")
c2CestasHpm = baseCestasHpm.mark_text(radiusOffset=10).encode(text="nb_pl:Q")
c1CestasHps = baseCestasHps.mark_arc(innerRadius=20, stroke="#fff")
c2CestasHps = baseCestasHps.mark_text(radiusOffset=10).encode(text="nb_pl:Q")
(c1CestasHpm + c2CestasHpm).configure_legend(titleFontSize=14, labelFontSize=14)


(c1CestasHps + c2CestasHps).configure_legend(titleFontSize=14, labelFontSize=14)


groupe, df_duree_cam1,df_duree_autres_cam = trajets.grouper_pl(passageNonTransit.loc[~passageNonTransit.reset_index().set_index(['created', 'camera_id', 'immat']).index.isin(
        dfPassagesPendulaire.set_index(['created', 'camera_id', 'immat']).index.tolist())].copy(),
                   '2019-01-31', '2019-02-13', 15, None)
